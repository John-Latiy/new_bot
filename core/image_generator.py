import os
import re
import random
from typing import Optional, List

import requests
from io import BytesIO
from PIL import Image
from openai import OpenAI

from config.settings import OPENAI_API_KEY, PIXABAY_API_KEY, MAX_COVERS
from utils.image_registry import (
    is_used,
    mark_used,
    is_file_saved,
    mark_file_saved,
    has_file_hash,
)


# –ö–ª–∏–µ–Ω—Ç OpenAI –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
client = OpenAI(api_key=OPENAI_API_KEY)


def sanitize_query(q: str) -> str:
    """–ü—Ä–∏–≤–µ—Å—Ç–∏ –∑–∞–ø—Ä–æ—Å –∫ –æ–ø—Ä—è—Ç–Ω–æ–º—É –≤–∏–¥—É: —É–±—Ä–∞—Ç—å –º–∞—Ä–∫–µ—Ä—ã —Å–ø–∏—Å–∫–æ–≤,
    –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã.
    """
    q = (q or "").strip()
    q = re.sub(r"^[^A-Za-z0-9]+", "", q)  # —É–±—Ä–∞—Ç—å –≤–µ–¥—É—â–∏–µ –¥–µ—Ñ–∏—Å—ã/–º–∞—Ä–∫–µ—Ä—ã
    q = re.sub(r"\s+", " ", q)
    return q


# –¢–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ñ–∏–ª—å—Ç—Ä—ã
FINANCE_WHITELIST = [
    "finance",
    "financial",
    "stock",
    "stocks",
    "market",
    "stock market",
    "trading",
    "trader",
    "chart",
    "charts",
    "candlestick",
    "ticker",
    "forex",
    "exchange",
    "economy",
    "bank",
    "money",
    "investment",
]

BLACKLIST = [
    "power supply",
    "psu",
    "computer",
    "motherboard",
    "gpu",
    "cpu",
    "cable",
    "plug",
    "socket",
    "server",
    "electronics",
]


def is_finance_related(text: str) -> bool:
    t = (text or "").lower()
    return any(w in t for w in FINANCE_WHITELIST)


def has_blacklisted(text: str) -> bool:
    t = (text or "").lower()
    return any(b in t for b in BLACKLIST)


def enrich_query(q: str) -> str:
    q = sanitize_query(q)
    # –£–±–∏—Ä–∞–µ–º —è–≤–Ω—ã–µ "–∂–µ–ª–µ–∑–Ω—ã–µ" —Ç–µ—Ä–º–∏–Ω—ã
    for b in BLACKLIST:
        q = re.sub(rf"\b{re.escape(b)}\b", "", q, flags=re.IGNORECASE)
    q = q.strip()
    # –î–æ–±–∞–≤–∏–º —è–∫–æ—Ä—å —Ç–µ–º–∞—Ç–∏–∫–∏, –µ—Å–ª–∏ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç
    if not is_finance_related(q):
        q = (q + " stock market").strip()
    return q


def generate_search_query(summary: str) -> str:
    """–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫–æ—Ä–æ—Ç–∫–∏–π –∞–Ω–≥–ª. –∑–∞–ø—Ä–æ—Å (1-3 —Å–ª–æ–≤–∞) –ø–æ–¥ —Ñ–æ—Ç–æ –Ω–∞ —Ç–µ–º—É
    —Ñ–∏–Ω–∞–Ω—Å–æ–≤/—Ä—ã–Ω–∫–æ–≤; —Å –ø–æ—Å–ª–µ–¥—É—é—â–∏–º –æ–±–æ–≥–∞—â–µ–Ω–∏–µ–º –∏ —á–∏—Å—Ç–∫–æ–π.
    """
    try:
        resp = client.chat.completions.create(
            model="gpt-3.5-turbo",
            temperature=0.3,
            messages=[
                {
                    "role": "system",
                    "content": (
                        "–¢—ã –ø–æ–º–æ—â–Ω–∏–∫ –ø–æ –ø–æ–∏—Å–∫—É —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π –î–õ–Ø –§–ò–ù–ê–ù–°–û–í–û–ô "
                        "–¢–ï–ú–ê–¢–ò–ö–ò. –ù–∞ –æ—Å–Ω–æ–≤–µ —Å–≤–æ–¥–∫–∏ –≤–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ –∫–æ—Ä–æ—Ç–∫–∏–π "
                        "–∞–Ω–≥–ª. –∑–∞–ø—Ä–æ—Å (1-3 —Å–ª–æ–≤–∞) –¥–ª—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ —Ñ–æ—Ç–æ (–Ω–µ AI). "
                        "–°—Ñ–æ–∫—É—Å–∏—Ä—É–π—Å—è –Ω–∞ —Ä—ã–Ω–∫–∞—Ö/—Ç—Ä–µ–π–¥–∏–Ω–≥–µ/–¥–µ–Ω—å–≥–∞—Ö: "
                        "stock market, trading floor, candlestick chart, "
                        "ticker, bank, money. "
                        "–ò–≥–Ω–æ—Ä–∏—Ä—É–π —ç–ª–µ–∫—Ç—Ä–æ–Ω–∏–∫—É/–∂–µ–ª–µ–∑–æ (computer, PSU, "
                        "cable –∏ —Ç.–ø.). "
                        "–í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ –∑–∞–ø—Ä–æ—Å."
                    ),
                },
                {"role": "user", "content": summary},
            ],
        )
        query = enrich_query(resp.choices[0].message.content or "")
        print("–ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å: " + query)
        return query or "finance business"
    except Exception as exc:
        print(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞: {exc}")
    return "finance business"


"""
–û—Å—Ç–∞–≤–ª–µ–Ω–∞ —Ç–æ–ª—å–∫–æ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Pixabay. –ü—É—Ç—å Pexels —É–¥–∞–ª—ë–Ω.
–†–∞—Å—à–∏—Ä–µ–Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è: –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –±–∞–∑–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –æ—Ç GPT.
"""


def generate_search_candidates(summary: str) -> List[str]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç 5-10 –∫–æ—Ä–æ—Ç–∫–∏—Ö –∞–Ω–≥–ª. –∑–∞–ø—Ä–æ—Å–æ–≤ (—Ç–µ–≥–æ–≤) –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–≤–æ–¥–∫–∏.
    –ü—Ä–∏–º–µ—Ä –æ—Ç–≤–µ—Ç–∞ GPT: "trading floor, candlestick chart, stock exchange, financial district, bull and bear, gold bars, oil barrels, central bank, press conference".
    """
    try:
        resp = client.chat.completions.create(
            model="gpt-3.5-turbo",
            temperature=0.4,
            messages=[
                {
                    "role": "system",
                    "content": (
                        "–¢—ã –ø–æ–º–æ—â–Ω–∏–∫ –ø–æ –ø–æ–∏—Å–∫—É —Ä–µ–∞–ª—å–Ω—ã—Ö —Ñ–æ—Ç–æ –¥–ª—è —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–π —Ç–µ–º—ã. "
                        "–í–µ—Ä–Ω–∏ 6-10 –∫–æ—Ä–æ—Ç–∫–∏—Ö –ê–ù–ì–õ–ò–ô–°–ö–ò–• —Ñ—Ä–∞–∑ (1-3 —Å–ª–æ–≤–∞ –∫–∞–∂–¥–∞—è), —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é. "
                        "–§–æ–∫—É—Å: —Ä—ã–Ω–∫–∏/—Ç—Ä–µ–π–¥–∏–Ω–≥/–¥–µ–Ω—å–≥–∏/–±–∞–Ω–∫–∏/—Å—ã—Ä—å—ë/—ç–∫–æ–Ω–æ–º–∏–∫–∞: trading floor, candlestick chart, stock exchange, trader at desk, financial district skyline, bull and bear, gold bars, oil barrels, energy market, central bank building, press conference, newspaper finance section. "
                        "–ò–≥–Ω–æ—Ä–∏—Ä—É–π —ç–ª–µ–∫—Ç—Ä–æ–Ω–∏–∫—É –∏ –∂–µ–ª–µ–∑–æ (computer, PSU, cable). –í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ —Å–ø–∏—Å–æ–∫, –±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π."
                    ),
                },
                {"role": "user", "content": summary},
            ],
        )
        raw = resp.choices[0].message.content or ""
        # –†–∞–∑–¥–µ–ª–∏–º –ø–æ –∑–∞–ø—è—Ç—ã–º/—Å—Ç—Ä–æ–∫–∞–º
        parts = re.split(r"[,\n]+", raw)
        clean = []
        seen = set()
        for p in parts:
            q = sanitize_query(p)
            if not q:
                continue
            q = enrich_query(q)
            k = q.lower()
            if k in seen:
                continue
            seen.add(k)
            clean.append(q)
            if len(clean) >= 10:
                break
        # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –≤—ã—à–ª–æ ‚Äî –ø–æ–¥—Å—Ç—Ä–∞—Ö—É–µ–º—Å—è –±–∞–∑–æ–π
        if not clean:
            clean = ["trading floor", "stock market", "candlestick chart", "financial district", "stock exchange building"]
        return clean
    except Exception as exc:
        print(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–ø–∏—Å–∫–∞ –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤: {exc}")
        return ["trading floor", "stock market", "candlestick chart", "banking"]


def _expand_query_variants(base: str) -> list:
    base = enrich_query(base)
    extras = [
        "trading floor",
        "trader at desk",
        "candlestick chart",
        "stock market",
        "stock exchange",
        "ticker",
        "financial markets",
        "financial district",
        "banking",
        "central bank",
        "press conference",
        "newspaper finance",
        "bull and bear",
        "gold bars",
        "oil barrels",
        "energy market",
        "forex trading",
        "cryptocurrency market",
    ]
    variants = [base]
    for e in extras:
        if e.lower() not in base.lower():
            variants.append(f"{base} {e}"[:80])
    # Deduplicate preserving order
    seen = set()
    uniq = []
    for v in variants:
        k = v.lower()
        if k not in seen:
            seen.add(k)
            uniq.append(v)
    return uniq[:10]


def search_pixabay_image(query) -> str:
    """–ò—â–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–∞ Pixabay –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä—è–º–æ–π URL.
    –£–ª—É—á—à–µ–Ω–æ: —Å–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –Ω–æ–≤—ã–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ —Å–ª—É—á–∞–π–Ω–æ
    –≤—ã–±–∏—Ä–∞–µ–º –æ–¥–Ω–æ, —á—Ç–æ–±—ã —Å–Ω–∏–∑–∏—Ç—å –ø–æ–≤—Ç–æ—Ä—è–µ–º–æ—Å—Ç—å.
    """
    try:
        if not (PIXABAY_API_KEY and PIXABAY_API_KEY.strip()):
            raise RuntimeError("PIXABAY_API_KEY is missing. Set it in .env")
        url = "https://pixabay.com/api/"
        params = {
            "key": PIXABAY_API_KEY or "",
            # q –∑–∞–¥–∞–¥–∏–º –Ω–∏–∂–µ –ø–æ –≤–∞—Ä–∏–∞–Ω—Ç–∞–º
            "image_type": "photo",
            "orientation": "all",
            "safesearch": "true",
            "per_page": 20,
            "order": "popular",
            "lang": "en",
        }
        base_list: List[str]
        if isinstance(query, (list, tuple)):
            base_list = list(query)
        else:
            base_list = [str(query)]

        # –°—Ñ–æ—Ä–º–∏—Ä—É–µ–º –æ–±—â–∏–π –ø—É–ª –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—Å–µ—Ö –±–∞–∑–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
        variants: List[str] = []
        for base in base_list:
            variants.extend(_expand_query_variants(base))
        # –î–æ–±–∞–≤–∏–º —Å–ª–µ–≥–∫–∞ –∑–∞—à—É–º–ª—ë–Ω–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã
        rand_suffix = ["global markets", "economy", "wall street", "business"]
        for b in base_list[:3]:
            for s in rand_suffix:
                v = enrich_query(f"{b} {s}")[:80]
                if v.lower() not in [x.lower() for x in variants]:
                    variants.append(v)

        total_used_skipped = 0
        for idx, variant in enumerate(variants, 1):
            pv = {**params, "q": variant}
            try:
                resp = requests.get(url, params=pv, timeout=20)
                resp.raise_for_status()
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ Pixabay (–≤–∞—Ä–∏–∞–Ω—Ç {idx}/{len(variants)}: '{variant}'): {e}")
                continue
            data = resp.json()
            hits = data.get("hits") or []
            candidates = []
            used_skipped = 0
            for h in hits:
                image_id = str(h.get("id"))
                if image_id and is_used("pixabay", image_id):
                    used_skipped += 1
                    continue
                tags = h.get("tags") or ""
                if has_blacklisted(tags) or not is_finance_related(tags + " " + variant):
                    continue
                image_url = (
                    h.get("largeImageURL")
                    or h.get("webformatURL")
                    or h.get("previewURL")
                )
                if image_url:
                    candidates.append((image_id, image_url))
            total_used_skipped += used_skipped
            if candidates:
                random.shuffle(candidates)
                image_id, image_url = candidates[0]
                print(
                    f"–ù–∞–π–¥–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (Pixabay): {image_url} | –≤–∞—Ä–∏–∞–Ω—Ç –∑–∞–ø—Ä–æ—Å–∞ {idx}/{len(variants)} '{variant}', –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤: {len(candidates)}, –ø—Ä–æ–ø—É—â–µ–Ω–æ —Ä–∞–Ω–µ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã—Ö: {used_skipped}, —Å—É–º–º–∞—Ä–Ω–æ –ø—Ä–æ–ø—É—â–µ–Ω–æ: {total_used_skipped}"
                )
                mark_used("pixabay", image_id or "", image_url, variant)
                return image_url
            else:
                print(f"–í–∞—Ä–∏–∞–Ω—Ç '{variant}' –Ω–µ –¥–∞–ª –Ω–æ–≤—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (used skipped={used_skipped}).")
        print(
            f"Pixabay: –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–æ–≤—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π. –í—Å–µ–≥–æ –ø—Ä–æ–ø—É—â–µ–Ω–æ —É–∂–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã—Ö: {total_used_skipped}."
        )
        raise RuntimeError("No suitable Pixabay images found for query (all variants exhausted)")
    except Exception as exc:
        print(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ Pixabay: {exc}")
        raise


def generate_image(
    prompt: str, filename: str = "data/final_cover.png"
) -> Optional[str]:
    """–ù–∞—Ö–æ–¥–∏—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ Pixabay –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –ª–æ–∫–∞–ª—å–Ω–æ.
    –¢–µ–ø–µ—Ä—å —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–¥ —É–Ω–∏–∫–∞–ª—å–Ω—ã–º –∏–º–µ–Ω–µ–º –≤–∏–¥–∞ data/covers/<id>.png, –∞
    —Ç–∞–∫–∂–µ –æ–±–Ω–æ–≤–ª—è–µ–º —Å–∏–º–ª–∏–Ω–∫/–∫–æ–ø–∏—é final_cover.png –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏.
    """
    try:
        print("–ü–æ–∏—Å–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (Pixabay)...")
        candidates = generate_search_candidates(prompt)
        # –ü–æ–¥—Å—Ç—Ä–∞—Ö—É–µ–º—Å—è –æ—Ç –ø–æ–≤—Ç–æ—Ä–æ–≤: –¥–æ 3 –≤–æ–ª–Ω —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º —à—É–º–æ–º
        last_error = None
        image_url = None
        for attempt in range(1, 4):
            try:
                image_url = search_pixabay_image(candidates)
                break
            except Exception as e:
                last_error = e
                # –¥–æ–±–∞–≤–∏–º —à—É–º –∫ –∫–∞–∂–¥–æ–º—É –∫–∞–Ω–¥–∏–¥–∞—Ç—É
                noisy = [enrich_query(f"{c} {random.choice(['global', 'markets', 'finance', 'economy'])}")[:80] for c in candidates]
                candidates = list(dict.fromkeys(noisy))  # dedup, —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø–æ—Ä—è–¥–æ–∫
        if not image_url:
            raise last_error or RuntimeError("No image found")

        print("–ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...")
        resp = requests.get(image_url, timeout=30)
        resp.raise_for_status()

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è
        os.makedirs("data/covers", exist_ok=True)
        # –ò–∑–≤–ª–µ—á—ë–º id –∏–∑ URL (—Ö—ç—à/—á–∏—Å–ª–∞ –ø–µ—Ä–µ–¥ _<size> .jpg/.jpeg/.png)
        uniq_id = None
        match = re.search(r"/get/([^/_]+)_\d+\.(?:jpg|jpeg|png)$", image_url, re.IGNORECASE)
        if match:
            uniq_id = match.group(1)
        if not uniq_id:
            # –§–æ–ª–±—ç–∫: —Ö—ç—à URL, —á—Ç–æ–±—ã –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å
            import hashlib
            uniq_id = hashlib.sha1(image_url.encode("utf-8")).hexdigest()[:40]
        unique_name = f"data/covers/{uniq_id}.png"

        # –ü–µ—Ä–µ–∫–æ–¥–∏—Ä—É–µ–º –≤ PNG, —á—Ç–æ–±—ã —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Å–æ–≤–ø–∞–¥–∞–ª–æ —Å —Å–æ–¥–µ—Ä–∂–∏–º—ã–º
        # –ü—Ä–æ–≤–µ—Ä–∏–º —Ö—ç—à —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –¥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è, —á—Ç–æ–±—ã –Ω–µ –ø–æ–≤—Ç–æ—Ä—è—Ç—å –æ–±–ª–æ–∂–∫–∏
        import hashlib
        content_hash = hashlib.sha256(resp.content).hexdigest()
        if has_file_hash(content_hash):
            print("‚ö†Ô∏è –°–∫–∞—á–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–∞–Ω–µ–µ —É–∂–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–æ—Å—å (–ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É). –ü—Ä–æ–±—É–µ–º –¥—Ä—É–≥–æ–π –≤–∞—Ä–∏–∞–Ω—Ç...")
            # –í—Ç–æ—Ä–∞—è –ø–æ–ø—ã—Ç–∫–∞: –¥—Ä—É–≥–æ–π –≤–∞—Ä–∏–∞–Ω—Ç –∑–∞–ø—Ä–æ—Å–∞
            try:
                alt_query = enrich_query(search_query + " finance markets")[:80]
                image_url = search_pixabay_image(alt_query)
                resp = requests.get(image_url, timeout=30)
                resp.raise_for_status()
                content_hash = hashlib.sha256(resp.content).hexdigest()
                if has_file_hash(content_hash):
                    print("‚ö†Ô∏è –ü–æ–≤—Ç–æ—Ä –∏ –ø–æ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–µ. –û—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å, —á—Ç–æ–±—ã –Ω–µ –∑–∞—Ü–∏–∫–ª–∏—Ç—å—Å—è.")
                else:
                    # –æ–±–Ω–æ–≤–∏–º uniq_id –ø–æ –≤—Ç–æ—Ä–æ–º—É URL
                    match = re.search(r"/get/([^/_]+)_\d+\.(?:jpg|jpeg|png)$", image_url, re.IGNORECASE)
                    if match:
                        uniq_id = match.group(1)
                    unique_name = f"data/covers/{uniq_id}.png"
            except Exception as _e:
                pass

        try:
            img = Image.open(BytesIO(resp.content)).convert("RGB")
            img.save(unique_name, format="PNG")
        except Exception:
            with open(unique_name, "wb") as f:
                f.write(resp.content)
        mark_file_saved(unique_name)

        # –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ–º —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π –ø—É—Ç—å final_cover.png
        try:
            # –ö–æ–ø–∏—Ä—É–µ–º (–Ω–µ —Å—Å—ã–ª–∫–∞) —á—Ç–æ–±—ã –≤–Ω–µ—à–Ω–∏–µ –∑–∞–≥—Ä—É–∑—á–∏–∫–∏ —Ä–∞–±–æ—Ç–∞–ª–∏ –æ–¥–∏–Ω–∞–∫–æ–≤–æ
            import shutil
            shutil.copyfile(unique_name, filename)
        except Exception as _e:
            pass

        # –†–æ—Ç–∞—Ü–∏—è: –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —á–∏—Å–ª–æ —Ñ–∞–π–ª–æ–≤ –≤ data/covers
        try:
            covers = sorted(
                [
                    os.path.join("data/covers", f)
                    for f in os.listdir("data/covers")
                    if f.lower().endswith(".png")
                ],
                key=lambda p: os.path.getmtime(p),
            )
            if len(covers) > MAX_COVERS:
                to_delete = covers[: len(covers) - MAX_COVERS]
                for old in to_delete:
                    try:
                        os.remove(old)
                        print(f"üßπ –£–¥–∞–ª—ë–Ω —Å—Ç–∞—Ä—ã–π cover: {old}")
                    except Exception:
                        pass
        except Exception as rot_e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Ä–æ—Ç–∞—Ü–∏–∏ –æ–±–ª–æ–∂–µ–∫: {rot_e}")

        print(f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {unique_name} (–∏ –æ–±–Ω–æ–≤–ª—ë–Ω {filename})")
        return unique_name
    except Exception as exc:
        print(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {exc}")
        return None
